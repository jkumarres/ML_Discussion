{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Activation, Dropout, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------- to load the hackathon data from local folder\n",
    "def load_hack_data():\n",
    "    #---- training data\n",
    "    images_tr = [];labels_tr =[]  \n",
    "    folder='training/background/'\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder,filename))\n",
    "        if img is not None:\n",
    "            images_tr.append(img)\n",
    "            labels_tr.append(0)\n",
    "    folder='training/hi/'\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder,filename))\n",
    "        if img is not None:\n",
    "            images_tr.append(img)\n",
    "            labels_tr.append(1)\n",
    "    c = list(zip(images_tr, labels_tr))\n",
    "    random.shuffle(c)\n",
    "    a, b = zip(*c)\n",
    "    train_ims = np.array(a)\n",
    "    train_labels = np.array(b)\n",
    "\n",
    "    #---- test data\n",
    "    images_test = [];labels_test=[]     \n",
    "    folder='test/'\n",
    "    for i in range(99):\n",
    "        filename=(str(i)+'.jpg')\n",
    "        img = cv2.imread(os.path.join(folder,filename))\n",
    "        if img is not None:\n",
    "            images_test.append(img)\n",
    "    test_ims = np.array(images_test)\n",
    "\n",
    "    labels_test=np.loadtxt('test_labels.txt')\n",
    "    test_labels = np.array(labels_test.astype(int))\n",
    "\n",
    "    return train_ims,train_labels,test_ims,test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------- from the hackathon drive to json\n",
    "def write_json(filename, result):\n",
    "    with open(filename, 'w') as outfile:\n",
    "        json.dump(result, outfile)\n",
    "\n",
    "def read_json(filename):\n",
    "    with open(filename, 'r') as outfile:\n",
    "        data =  json.load(outfile)\n",
    "    return data\n",
    "\n",
    "def generate_sample_file(filename,labels_predicted):\n",
    "    res = {}\n",
    "    for i in range(1,99):\n",
    "        test_set = str(i) + '.png'\n",
    "        res[test_set] = int(np.argmax(labels_predicted[i-1]))\n",
    "    write_json(filename, res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- data upload\n",
    "train_images, train_labels, test_images,test_labels = load_hack_data()\n",
    "#train_labels = to_categorical(train_labels)\n",
    "#test_labels = to_categorical(test_labels)\n",
    "\n",
    "#--- thresholding\n",
    "Threshold = 25\n",
    "train_images = (train_images > Threshold)\n",
    "test_images = (test_images > Threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_filters = 64\n",
    "kernel_size = 4\n",
    "strides = 1\n",
    "pool_size = 2\n",
    "nodes = 1024\n",
    "image_shape = train_images.shape[1:]\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "#-----------------First----------------------------------\n",
    "model.add(Conv2D(32, kernel_size, strides, padding=\"valid\",input_shape = image_shape))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size, padding='valid'))\n",
    "\n",
    "#-----------------Second---------------------------------\n",
    "model.add(Conv2D(num_filters, kernel_size, strides, padding=\"valid\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size, padding='valid'))\n",
    "\n",
    "#-----------------Third----------------------------------\n",
    "model.add(Flatten())\n",
    "model.add(Dense(nodes))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "#------------output--------------------------------------\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "#--------------------------------------------------------\n",
    "#opt = SGD(learning_rate=0.0001, momentum=0.9)\n",
    "#model.compile(loss = \"categorical_crossentropy\", optimizer = \"Adam\", metrics= ['accuracy'])\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "              metrics=['accuracy'])\n",
    "#model.summary()\n",
    "\n",
    "#--------- model training -------------\n",
    "history = model.fit(train_images, train_labels,batch_size=128, epochs=20, validation_split = 0.010)\n",
    "\n",
    "#--------- model predicts test data labels ------\n",
    "predict_labels = model.predict(test_images)\n",
    "generate_sample_file('result.json',predict_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
